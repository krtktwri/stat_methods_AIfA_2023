{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P11: Introduction to ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem sheet, we will revisit photometric redshift estimation and we will train a simple NN to estimate galaxy redshift from $\\mathrm{mag}_u, \\mathrm{mag}_g, \\mathrm{mag}_r, \\mathrm{mag}_i, \\mathrm{mag}_z$ photometry. We will use the spectroscopic SDSS galaxy sample as an example.\n",
    "\n",
    "For this, we will need `astroML` and `pytorch` (if you are more familar with another Deep Learning package you can of course use that instead)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Get SDSS data using `astroML`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python package `astroML` contains a number of useful data sets. In particular, it contains a sample of SDSS galaxies for which both photometric and spectroscopic measurements have been obtained. For all galaxies in this sample, we have access to photometrically-determined magnitudes $\\mathrm{mag}_u, \\mathrm{mag}_g, \\mathrm{mag}_r, \\mathrm{mag}_i, \\mathrm{mag}_z$ and spectroscopically-determined redshift $z$. We will use this sample to train a neural network to predict redshift $z$ from 5 input magnitudes $\\mathrm{mag}_u, \\mathrm{mag}_g, \\mathrm{mag}_r, \\mathrm{mag}_i, \\mathrm{mag}_z$, treating the spectroscopically determined redshift as ground truth.\n",
    "\n",
    "(i) Fetch the matched SDSS sample from `astroML.datasets` making use of the routine `fetch_sdss_specgals()`.\n",
    "\n",
    "(ii) Inspect the data set, retrieve the magnitudes $\\mathrm{mag}_u, \\mathrm{mag}_g, \\mathrm{mag}_r, \\mathrm{mag}_i, \\mathrm{mag}_z$ and redshift $z$.\n",
    "\n",
    "(iii) Plot the redshift distribution of the SDSS galaxies.\n",
    "\n",
    "(iv) Plot the color-magnitude diagram $\\mathrm{mag}_r$ vs. $\\mathrm{mag}_u-\\mathrm{mag}_r$ of the galaxies. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 2: Build NN with `pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pytorch` to build a neural network consisting of an input layer (the data itself), a hidden linear layer, and a linear output layer. As activation function, you can use ReLU. Following what we discussed in class, it is simplest if you do not apply the activation function to the output layer.\n",
    "\n",
    "Below you can find a code snippet that defines your NN. The initialization step defines the pieces needed for your network and the `forward` function describes how to combine them in the forward pass through the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class model_1hl(nn.Module):\n",
    "    def __init__(self, nh1):\n",
    "        '''\n",
    "        Class initialization.\n",
    "        Args:\n",
    "        nh1 (:obj:`integer`): number of neurons in hidden layer\n",
    "        '''\n",
    "        \n",
    "        super().__init__() # Call base class' init function\n",
    "        self.fc_h = # Linear hidden layer (use nn.Linear) #input are the 5 colors\n",
    "        self.fc_o = # Linear output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = # Apply ReLU to output from fc_h (use nn.functional.ReLU)\n",
    "        z = # Pass h though output layer\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will prepare our data for NN training.\n",
    "\n",
    "(i) Split the data from problem 1 into three subsamples: training set, validation set, and test set. As a first approach you can use $70\\%$ of the data for training, and $15\\%$ each for validation and testing.\n",
    "\n",
    "(ii) NN training is often more efficient when using normalized data, as this improves the performance of gradient descent algorithms. Using the data from (i), normalize it to zero mean and variance 1. \n",
    "\n",
    "(iii) Discuss if the normalization should be applied to the entire dataset or only to the training set? How to normalize the validation and test sets?\n",
    "\n",
    "**Hint:** To interface with `pytorch`, you can either use the functionality in `torch.utils.data` provided by `TensorDataset` and `tensor`, or you can also define your own dataset class. Once you have created your dataset, you can create a data loader using `DataLoader`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: NN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will write a routine to train our NN with `pytorch`. Note the following:\n",
    "\n",
    "- As loss function, you can use the mean squared error.\n",
    "- You can use the stochastic gradient descent optimizer.\n",
    "- Log the training, validation loss for each epoch as numpy arrays.\n",
    "- Use the validation loss to pick the optimal model for a given architecture and choice of hyperparameters, i.e. pick the model with the lowest validation loss.\n",
    "\n",
    "(i) Once you have set up the training routine, train your model for 100 epochs and save the best-performing model.\n",
    "\n",
    "(ii) Look at the loss curves as a function of training epoch and discuss your results. Have you trained the model long enough?\n",
    "\n",
    "(iii) Experiment with changing hyperparameters, especially the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Evaluate the performance of your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the test set to evaluate the performance of your NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
